{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanfengzhai/PIDOC/blob/main/vanderPol/vanderPol_Fig4_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv3cUue4Ieq_",
        "outputId": "9d6fa851-63d1-46aa-b611-23f711dcd1ec"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 1.15.0\n",
            "Uninstalling tensorflow-1.15.0:\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall tensorflow==2.8.0\n",
        "!pip install tensorflow==1.15.0\n",
        "import tensorflow as tf\n",
        "# import deepxde as dde\n",
        "import numpy as np\n",
        "from scipy import linspace\n",
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "import time\n",
        "import timeit\n",
        "# import tensorflow_probability as tfp\n",
        "\n",
        "# tf.disable_v2_behavior()\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvqAyqq3IwUF",
        "outputId": "de3f661b-c814-4736-cbcc-3def7daf00e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "\n",
            "6.072e+03\n",
            "1.563e+04\n",
            "6.071e+03\n",
            "6.070e+03\n",
            "6.069e+03\n",
            "6.069e+03\n",
            "6.069e+03\n",
            "6.068e+03\n",
            "6.066e+03\n",
            "6.066e+03\n",
            "6.065e+03\n",
            "6.095e+03\n",
            "6.063e+03\n",
            "6.061e+03\n",
            "6.061e+03\n",
            "6.060e+03\n",
            "6.059e+03\n",
            "6.058e+03\n",
            "6.055e+03\n",
            "6.052e+03\n",
            "6.050e+03\n",
            "6.050e+03\n",
            "6.050e+03\n",
            "6.049e+03\n",
            "6.049e+03\n",
            "6.048e+03\n",
            "6.046e+03\n",
            "6.043e+03\n",
            "6.043e+03\n",
            "6.042e+03\n",
            "6.040e+03\n",
            "6.040e+03\n",
            "6.039e+03\n",
            "6.038e+03\n",
            "6.037e+03\n",
            "6.036e+03\n",
            "6.039e+03\n",
            "6.036e+03\n",
            "6.035e+03\n",
            "6.035e+03\n",
            "6.035e+03\n",
            "6.034e+03\n",
            "6.032e+03\n",
            "6.030e+03\n",
            "6.027e+03\n",
            "6.230e+03\n",
            "6.024e+03\n",
            "6.037e+03\n",
            "6.020e+03\n",
            "6.020e+03\n",
            "6.018e+03\n",
            "6.015e+03\n",
            "6.004e+03\n",
            "1.840e+04\n",
            "6.003e+03\n",
            "6.002e+03\n",
            "9.369e+03\n",
            "5.996e+03\n",
            "5.990e+03\n",
            "6.257e+03\n",
            "5.978e+03\n",
            "1.577e+07\n",
            "5.975e+03\n",
            "9.175e+03\n",
            "5.971e+03\n",
            "5.966e+03\n",
            "5.943e+03\n",
            "5.500e+03\n",
            "2.370e+04\n",
            "5.437e+03\n",
            "9.892e+03\n",
            "5.314e+03\n",
            "7.648e+04\n",
            "5.201e+03\n",
            "6.279e+03\n",
            "5.068e+03\n",
            "5.073e+03\n",
            "5.000e+03\n",
            "5.130e+03\n",
            "4.965e+03\n",
            "4.907e+03\n",
            "4.901e+03\n",
            "4.897e+03\n",
            "4.896e+03\n",
            "4.886e+03\n",
            "4.878e+03\n",
            "4.868e+03\n",
            "4.842e+03\n",
            "4.802e+03\n",
            "4.772e+03\n",
            "4.753e+03\n",
            "4.730e+03\n",
            "4.747e+03\n",
            "4.720e+03\n",
            "4.696e+03\n",
            "4.648e+03\n",
            "4.665e+03\n",
            "4.628e+03\n",
            "4.618e+03\n",
            "4.609e+03\n",
            "4.605e+03\n",
            "4.602e+03\n",
            "4.603e+03\n",
            "4.598e+03\n",
            "4.591e+03\n",
            "4.584e+03\n",
            "4.585e+03\n",
            "4.582e+03\n",
            "4.588e+03\n",
            "4.579e+03\n",
            "4.576e+03\n",
            "4.570e+03\n",
            "4.555e+03\n",
            "4.550e+03\n",
            "4.540e+03\n",
            "4.555e+03\n",
            "4.517e+03\n",
            "4.484e+03\n",
            "4.408e+03\n",
            "4.371e+03\n",
            "4.317e+03\n",
            "4.314e+03\n",
            "4.295e+03\n",
            "4.285e+03\n",
            "4.288e+03\n",
            "4.279e+03\n",
            "4.275e+03\n",
            "4.270e+03\n",
            "4.264e+03\n",
            "4.259e+03\n",
            "4.256e+03\n",
            "4.252e+03\n",
            "4.248e+03\n",
            "4.241e+03\n",
            "4.231e+03\n",
            "4.205e+03\n",
            "4.179e+03\n",
            "4.165e+03\n",
            "4.156e+03\n",
            "4.148e+03\n",
            "4.136e+03\n",
            "4.128e+03\n",
            "4.124e+03\n",
            "4.118e+03\n",
            "4.116e+03\n",
            "4.113e+03\n",
            "4.111e+03\n",
            "4.109e+03\n",
            "4.106e+03\n",
            "4.097e+03\n",
            "4.074e+03\n",
            "4.050e+03\n",
            "4.076e+03\n",
            "4.034e+03\n",
            "4.023e+03\n",
            "4.023e+03\n",
            "4.007e+03\n",
            "3.992e+03\n",
            "3.976e+03\n",
            "3.899e+03\n",
            "3.844e+03\n",
            "3.831e+03\n",
            "3.807e+03\n",
            "3.769e+03\n",
            "4.345e+03\n",
            "3.752e+03\n",
            "3.748e+03\n",
            "3.734e+03\n",
            "3.727e+03\n",
            "3.727e+03\n",
            "3.717e+03\n",
            "3.708e+03\n",
            "3.696e+03\n",
            "3.704e+03\n",
            "3.691e+03\n",
            "3.685e+03\n",
            "3.675e+03\n",
            "3.665e+03\n",
            "3.654e+03\n",
            "3.646e+03\n",
            "3.626e+03\n",
            "3.608e+03\n",
            "3.600e+03\n",
            "3.593e+03\n",
            "3.595e+03\n",
            "3.590e+03\n",
            "3.582e+03\n",
            "3.561e+03\n",
            "3.550e+03\n",
            "3.547e+03\n",
            "3.544e+03\n",
            "3.541e+03\n",
            "3.535e+03\n",
            "3.530e+03\n",
            "3.520e+03\n",
            "3.513e+03\n",
            "3.503e+03\n",
            "3.499e+03\n",
            "3.499e+03\n",
            "3.495e+03\n",
            "3.494e+03\n",
            "3.493e+03\n",
            "3.491e+03\n",
            "3.488e+03\n",
            "3.480e+03\n",
            "3.467e+03\n",
            "3.456e+03\n",
            "3.442e+03\n",
            "3.434e+03\n",
            "3.423e+03\n",
            "3.417e+03\n",
            "3.395e+03\n",
            "3.386e+03\n",
            "3.376e+03\n",
            "3.368e+03\n",
            "3.365e+03\n",
            "3.358e+03\n",
            "3.354e+03\n",
            "3.351e+03\n",
            "3.360e+03\n",
            "3.346e+03\n",
            "3.338e+03\n",
            "3.329e+03\n",
            "3.382e+03\n",
            "3.322e+03\n",
            "3.328e+03\n",
            "3.314e+03\n",
            "3.300e+03\n",
            "3.297e+03\n",
            "3.291e+03\n",
            "3.293e+03\n",
            "3.284e+03\n",
            "3.308e+03\n",
            "3.280e+03\n",
            "3.282e+03\n",
            "3.278e+03\n",
            "3.277e+03\n",
            "3.275e+03\n",
            "3.273e+03\n",
            "3.268e+03\n",
            "3.258e+03\n",
            "3.242e+03\n",
            "3.221e+03\n",
            "3.440e+03\n",
            "3.207e+03\n",
            "4.817e+03\n",
            "3.175e+03\n",
            "3.149e+03\n",
            "3.134e+03\n",
            "3.117e+03\n",
            "3.089e+03\n",
            "3.242e+03\n",
            "3.071e+03\n",
            "3.047e+03\n",
            "3.025e+03\n",
            "3.002e+03\n",
            "2.991e+03\n",
            "2.966e+03\n",
            "2.959e+03\n",
            "2.942e+03\n",
            "2.935e+03\n",
            "2.925e+03\n",
            "2.921e+03\n",
            "2.919e+03\n",
            "2.917e+03\n",
            "2.916e+03\n",
            "2.913e+03\n",
            "2.910e+03\n",
            "2.906e+03\n",
            "2.897e+03\n",
            "2.887e+03\n",
            "2.885e+03\n",
            "2.876e+03\n",
            "2.877e+03\n",
            "2.873e+03\n",
            "2.871e+03\n",
            "2.869e+03\n",
            "2.869e+03\n",
            "2.866e+03\n",
            "2.863e+03\n",
            "2.858e+03\n",
            "2.853e+03\n",
            "2.848e+03\n",
            "2.841e+03\n",
            "2.829e+03\n",
            "2.814e+03\n",
            "2.783e+03\n",
            "2.798e+03\n",
            "2.758e+03\n",
            "2.759e+03\n",
            "2.737e+03\n",
            "2.714e+03\n",
            "2.703e+03\n",
            "2.695e+03\n",
            "2.690e+03\n",
            "2.682e+03\n",
            "2.661e+03\n",
            "2.642e+03\n",
            "2.608e+03\n",
            "2.583e+03\n",
            "2.609e+03\n",
            "2.574e+03\n",
            "2.579e+03\n",
            "2.568e+03\n",
            "2.561e+03\n",
            "2.551e+03\n",
            "2.542e+03\n",
            "2.516e+03\n",
            "2.474e+03\n",
            "2.438e+03\n",
            "2.397e+03\n",
            "2.356e+03\n",
            "2.298e+03\n",
            "2.250e+03\n",
            "2.205e+03\n",
            "2.715e+03\n",
            "2.186e+03\n",
            "2.185e+03\n",
            "2.155e+03\n",
            "2.124e+03\n",
            "2.109e+03\n",
            "2.099e+03\n",
            "2.089e+03\n",
            "2.069e+03\n",
            "2.075e+03\n",
            "2.058e+03\n",
            "2.044e+03\n",
            "2.036e+03\n",
            "2.030e+03\n",
            "2.019e+03\n",
            "1.988e+03\n",
            "1.959e+03\n",
            "1.921e+03\n",
            "1.897e+03\n",
            "1.884e+03\n",
            "1.873e+03\n",
            "1.862e+03\n",
            "1.852e+03\n",
            "1.840e+03\n",
            "1.833e+03\n",
            "1.827e+03\n",
            "1.810e+03\n",
            "1.800e+03\n",
            "1.788e+03\n",
            "1.777e+03\n",
            "1.762e+03\n",
            "1.735e+03\n",
            "1.708e+03\n",
            "1.817e+03\n",
            "1.675e+03\n",
            "1.726e+03\n",
            "1.608e+03\n",
            "1.601e+03\n",
            "1.577e+03\n",
            "1.566e+03\n",
            "1.552e+03\n",
            "1.524e+03\n",
            "1.469e+03\n",
            "1.411e+03\n",
            "1.350e+03\n",
            "1.302e+03\n",
            "1.276e+03\n",
            "1.328e+03\n",
            "1.259e+03\n",
            "1.313e+03\n",
            "1.249e+03\n",
            "1.249e+03\n",
            "1.237e+03\n",
            "1.230e+03\n",
            "1.219e+03\n",
            "1.207e+03\n",
            "1.172e+03\n",
            "1.145e+03\n",
            "1.130e+03\n",
            "1.126e+03\n",
            "1.123e+03\n",
            "1.119e+03\n",
            "1.113e+03\n",
            "1.107e+03\n",
            "1.103e+03\n",
            "1.102e+03\n",
            "1.099e+03\n",
            "1.093e+03\n",
            "1.080e+03\n",
            "1.068e+03\n",
            "1.065e+03\n",
            "1.059e+03\n",
            "1.057e+03\n",
            "1.056e+03\n",
            "1.055e+03\n",
            "1.053e+03\n",
            "1.050e+03\n",
            "1.045e+03\n",
            "1.038e+03\n",
            "1.031e+03\n",
            "1.020e+03\n",
            "1.012e+03\n",
            "1.006e+03\n",
            "1.002e+03\n",
            "9.966e+02\n",
            "9.898e+02\n",
            "9.810e+02\n",
            "9.720e+02\n",
            "9.682e+02\n",
            "9.681e+02\n",
            "9.624e+02\n",
            "9.615e+02\n",
            "9.599e+02\n",
            "9.592e+02\n",
            "9.571e+02\n",
            "9.534e+02\n",
            "9.474e+02\n",
            "9.403e+02\n",
            "9.350e+02\n",
            "9.309e+02\n",
            "9.286e+02\n",
            "9.263e+02\n",
            "9.245e+02\n",
            "9.204e+02\n",
            "9.133e+02\n",
            "9.024e+02\n",
            "8.891e+02\n",
            "8.914e+02\n",
            "8.836e+02\n",
            "1.015e+03\n",
            "8.783e+02\n",
            "8.742e+02\n",
            "8.695e+02\n",
            "8.657e+02\n",
            "8.597e+02\n",
            "8.463e+02\n",
            "8.327e+02\n",
            "8.156e+02\n",
            "8.057e+02\n",
            "7.993e+02\n",
            "7.900e+02\n",
            "7.935e+02\n",
            "7.853e+02\n",
            "7.809e+02\n",
            "7.762e+02\n",
            "7.720e+02\n",
            "7.648e+02\n",
            "7.551e+02\n",
            "7.446e+02\n",
            "7.320e+02\n",
            "7.155e+02\n",
            "6.937e+02\n",
            "6.561e+02\n",
            "6.367e+02\n",
            "6.292e+02\n",
            "6.441e+02\n",
            "6.201e+02\n",
            "6.141e+02\n",
            "6.105e+02\n",
            "5.980e+02\n",
            "5.886e+02\n",
            "5.691e+02\n",
            "5.496e+02\n",
            "5.505e+02\n",
            "5.336e+02\n",
            "5.068e+02\n",
            "4.805e+02\n",
            "4.878e+02\n",
            "4.702e+02\n",
            "4.574e+02\n",
            "4.506e+02\n",
            "4.408e+02\n",
            "4.297e+02\n",
            "4.184e+02\n",
            "4.055e+02\n",
            "3.886e+02\n",
            "3.734e+02\n",
            "3.565e+02\n",
            "3.378e+02\n",
            "3.247e+02\n",
            "3.340e+02\n",
            "3.194e+02\n",
            "3.146e+02\n",
            "3.116e+02\n",
            "3.095e+02\n",
            "3.062e+02\n",
            "3.041e+02\n",
            "3.021e+02\n",
            "2.997e+02\n",
            "2.970e+02\n",
            "2.948e+02\n",
            "2.990e+02\n",
            "2.935e+02\n",
            "2.920e+02\n",
            "2.909e+02\n",
            "2.897e+02\n",
            "2.881e+02\n",
            "2.852e+02\n",
            "2.821e+02\n",
            "2.781e+02\n",
            "2.758e+02\n",
            "2.734e+02\n",
            "2.723e+02\n",
            "2.712e+02\n",
            "2.705e+02\n",
            "2.698e+02\n",
            "2.693e+02\n",
            "2.686e+02\n",
            "2.681e+02\n",
            "2.676e+02\n",
            "2.670e+02\n",
            "2.661e+02\n",
            "2.651e+02\n",
            "2.684e+02\n",
            "2.646e+02\n",
            "2.635e+02\n",
            "2.629e+02\n",
            "2.622e+02\n",
            "2.616e+02\n",
            "2.607e+02\n",
            "2.602e+02\n",
            "2.596e+02\n",
            "2.590e+02\n",
            "2.586e+02\n",
            "2.581e+02\n",
            "2.577e+02\n",
            "2.568e+02\n",
            "2.555e+02\n",
            "2.545e+02\n",
            "2.538e+02\n",
            "2.531e+02\n",
            "2.526e+02\n",
            "2.520e+02\n",
            "2.518e+02\n",
            "2.516e+02\n",
            "2.513e+02\n",
            "2.511e+02\n",
            "2.507e+02\n",
            "2.502e+02\n",
            "2.499e+02\n",
            "2.496e+02\n",
            "2.493e+02\n",
            "2.491e+02\n",
            "2.488e+02\n",
            "2.484e+02\n",
            "2.481e+02\n",
            "2.477e+02\n",
            "2.472e+02\n",
            "2.465e+02\n",
            "2.450e+02\n",
            "2.430e+02\n",
            "2.422e+02\n",
            "2.455e+02\n",
            "2.411e+02\n",
            "2.408e+02\n",
            "2.400e+02\n",
            "2.396e+02\n",
            "2.392e+02\n",
            "2.387e+02\n",
            "2.383e+02\n",
            "2.378e+02\n",
            "2.371e+02\n",
            "2.366e+02\n",
            "2.363e+02\n",
            "2.362e+02\n",
            "2.361e+02\n",
            "2.359e+02\n",
            "2.358e+02\n",
            "2.356e+02\n",
            "2.354e+02\n",
            "2.353e+02\n",
            "2.352e+02\n",
            "2.351e+02\n",
            "2.350e+02\n",
            "2.348e+02\n",
            "2.346e+02\n",
            "2.343e+02\n",
            "2.341e+02\n",
            "2.340e+02\n",
            "2.340e+02\n",
            "2.339e+02\n",
            "2.339e+02\n",
            "2.338e+02\n",
            "2.337e+02\n",
            "2.345e+02\n",
            "2.337e+02\n",
            "2.335e+02\n",
            "2.332e+02\n",
            "2.331e+02\n",
            "2.330e+02\n",
            "2.329e+02\n",
            "2.327e+02\n",
            "2.326e+02\n",
            "2.325e+02\n",
            "2.325e+02\n",
            "2.325e+02\n",
            "2.324e+02\n",
            "2.324e+02\n",
            "2.323e+02\n",
            "2.323e+02\n",
            "2.322e+02\n",
            "2.322e+02\n",
            "2.321e+02\n",
            "2.318e+02\n",
            "2.314e+02\n",
            "2.309e+02\n",
            "2.305e+02\n",
            "2.303e+02\n",
            "2.302e+02\n",
            "2.301e+02\n",
            "2.300e+02\n",
            "2.299e+02\n",
            "2.298e+02\n",
            "2.304e+02\n",
            "2.298e+02\n",
            "2.297e+02\n",
            "2.297e+02\n",
            "2.297e+02\n",
            "2.296e+02\n",
            "2.296e+02\n",
            "2.296e+02\n",
            "2.296e+02\n",
            "2.295e+02\n",
            "2.294e+02\n",
            "2.293e+02\n",
            "2.292e+02\n",
            "2.291e+02\n",
            "2.290e+02\n",
            "2.289e+02\n",
            "2.288e+02\n",
            "2.287e+02\n",
            "2.286e+02\n",
            "2.286e+02\n",
            "2.286e+02\n",
            "2.285e+02\n",
            "2.285e+02\n",
            "2.285e+02\n",
            "2.285e+02\n",
            "2.284e+02\n",
            "2.284e+02\n",
            "2.284e+02\n",
            "2.284e+02\n",
            "2.283e+02\n",
            "2.283e+02\n",
            "2.283e+02\n",
            "2.283e+02\n",
            "2.283e+02\n",
            "2.282e+02\n",
            "2.282e+02\n",
            "2.282e+02\n",
            "2.281e+02\n",
            "2.281e+02\n",
            "2.280e+02\n",
            "2.282e+02\n",
            "2.279e+02\n",
            "2.278e+02\n",
            "2.277e+02\n",
            "2.276e+02\n",
            "2.277e+02\n",
            "2.275e+02\n",
            "2.275e+02\n",
            "2.274e+02\n",
            "2.273e+02\n",
            "2.273e+02\n",
            "2.272e+02\n",
            "2.271e+02\n",
            "2.274e+02\n",
            "2.270e+02\n",
            "2.269e+02\n",
            "2.267e+02\n",
            "2.266e+02\n",
            "2.272e+02\n",
            "2.265e+02\n",
            "2.263e+02\n",
            "2.261e+02\n",
            "2.260e+02\n",
            "2.259e+02\n",
            "2.258e+02\n",
            "2.257e+02\n",
            "2.253e+02\n",
            "2.249e+02\n",
            "2.245e+02\n",
            "2.241e+02\n",
            "2.237e+02\n",
            "2.236e+02\n",
            "2.235e+02\n",
            "2.234e+02\n",
            "2.233e+02\n",
            "2.233e+02\n",
            "2.232e+02\n",
            "2.232e+02\n",
            "2.231e+02\n",
            "2.230e+02\n",
            "2.230e+02\n",
            "2.229e+02\n",
            "2.231e+02\n",
            "2.228e+02\n",
            "2.227e+02\n",
            "2.225e+02\n",
            "2.224e+02\n",
            "2.223e+02\n",
            "2.220e+02\n",
            "2.218e+02\n",
            "2.216e+02\n",
            "2.217e+02\n",
            "2.215e+02\n",
            "2.213e+02\n",
            "2.212e+02\n",
            "2.212e+02\n",
            "2.211e+02\n",
            "2.209e+02\n",
            "2.207e+02\n",
            "2.204e+02\n",
            "2.205e+02\n",
            "2.202e+02\n",
            "2.199e+02\n",
            "2.197e+02\n",
            "2.196e+02\n",
            "2.194e+02\n",
            "2.193e+02\n",
            "2.192e+02\n",
            "2.191e+02\n",
            "2.190e+02\n",
            "2.190e+02\n",
            "2.190e+02\n",
            "2.189e+02\n",
            "2.189e+02\n",
            "2.188e+02\n",
            "2.188e+02\n",
            "2.186e+02\n",
            "2.184e+02\n",
            "2.182e+02\n",
            "2.180e+02\n",
            "2.178e+02\n",
            "2.178e+02\n",
            "2.177e+02\n",
            "2.176e+02\n",
            "2.174e+02\n",
            "2.172e+02\n",
            "2.170e+02\n",
            "2.174e+02\n",
            "2.168e+02\n",
            "2.166e+02\n",
            "2.165e+02\n",
            "2.162e+02\n",
            "2.161e+02\n",
            "2.159e+02\n",
            "2.157e+02\n",
            "2.157e+02\n",
            "2.156e+02\n",
            "2.156e+02\n",
            "2.155e+02\n",
            "2.155e+02\n",
            "2.154e+02\n",
            "2.153e+02\n",
            "2.152e+02\n",
            "2.151e+02\n",
            "2.151e+02\n",
            "2.150e+02\n",
            "2.149e+02\n",
            "2.149e+02\n",
            "2.148e+02\n",
            "2.147e+02\n",
            "2.147e+02\n",
            "2.146e+02\n",
            "2.144e+02\n",
            "2.143e+02\n",
            "2.141e+02\n",
            "2.140e+02\n",
            "2.139e+02\n",
            "2.138e+02\n",
            "2.137e+02\n",
            "2.136e+02\n",
            "2.135e+02\n",
            "2.135e+02\n",
            "2.135e+02\n",
            "2.134e+02\n",
            "2.134e+02\n",
            "2.133e+02\n",
            "2.133e+02\n",
            "2.132e+02\n",
            "2.131e+02\n",
            "2.131e+02\n",
            "2.131e+02\n",
            "2.130e+02\n",
            "2.130e+02\n",
            "2.130e+02\n",
            "2.129e+02\n",
            "2.129e+02\n",
            "2.128e+02\n",
            "2.128e+02\n",
            "2.127e+02\n",
            "2.126e+02\n",
            "2.126e+02\n",
            "2.125e+02\n",
            "2.125e+02\n",
            "2.125e+02\n",
            "2.124e+02\n",
            "2.124e+02\n",
            "2.124e+02\n",
            "2.123e+02\n",
            "2.123e+02\n",
            "2.123e+02\n",
            "2.122e+02\n",
            "2.122e+02\n",
            "2.121e+02\n",
            "2.120e+02\n",
            "2.120e+02\n",
            "2.119e+02\n",
            "2.118e+02\n",
            "2.118e+02\n",
            "2.118e+02\n",
            "2.118e+02\n",
            "2.117e+02\n",
            "2.117e+02\n",
            "2.116e+02\n",
            "2.116e+02\n",
            "2.115e+02\n",
            "2.115e+02\n",
            "2.115e+02\n",
            "2.114e+02\n",
            "2.114e+02\n",
            "2.113e+02\n",
            "2.113e+02\n",
            "2.112e+02\n",
            "2.112e+02\n",
            "2.111e+02\n",
            "2.111e+02\n",
            "2.110e+02\n",
            "2.109e+02\n",
            "2.109e+02\n",
            "2.107e+02\n",
            "2.107e+02\n",
            "2.106e+02\n",
            "2.108e+02\n",
            "2.104e+02\n",
            "2.103e+02\n",
            "2.102e+02\n",
            "2.102e+02\n",
            "2.100e+02\n",
            "2.099e+02\n",
            "2.098e+02\n",
            "2.098e+02\n",
            "2.097e+02\n",
            "2.097e+02\n",
            "2.097e+02\n",
            "2.097e+02\n",
            "2.097e+02\n",
            "2.096e+02\n",
            "2.095e+02\n",
            "2.094e+02\n",
            "2.093e+02\n",
            "2.091e+02\n",
            "2.091e+02\n",
            "2.090e+02\n",
            "2.089e+02\n",
            "2.088e+02\n",
            "2.086e+02\n",
            "2.085e+02\n",
            "2.084e+02\n",
            "2.083e+02\n",
            "2.082e+02\n",
            "2.082e+02\n",
            "2.081e+02\n",
            "2.081e+02\n",
            "2.080e+02\n",
            "2.079e+02\n",
            "2.078e+02\n",
            "2.078e+02\n",
            "2.077e+02\n",
            "2.077e+02\n",
            "2.076e+02\n",
            "2.076e+02\n",
            "2.074e+02\n",
            "2.073e+02\n",
            "2.072e+02\n",
            "2.071e+02\n",
            "2.070e+02\n",
            "2.070e+02\n",
            "2.069e+02\n",
            "2.069e+02\n",
            "2.069e+02\n",
            "2.068e+02\n",
            "2.068e+02\n",
            "2.068e+02\n",
            "2.067e+02\n",
            "2.067e+02\n",
            "2.066e+02\n",
            "2.066e+02\n",
            "2.066e+02\n",
            "2.065e+02\n",
            "2.065e+02\n",
            "2.064e+02\n",
            "2.064e+02\n",
            "2.064e+02\n",
            "2.063e+02\n",
            "2.063e+02\n",
            "2.063e+02\n",
            "2.063e+02\n",
            "2.063e+02\n",
            "2.062e+02\n",
            "2.062e+02\n",
            "2.062e+02\n",
            "2.062e+02\n",
            "2.062e+02\n",
            "2.061e+02\n",
            "2.061e+02\n",
            "2.061e+02\n",
            "2.061e+02\n",
            "2.060e+02\n",
            "2.060e+02\n",
            "2.060e+02\n",
            "2.060e+02\n",
            "2.059e+02\n",
            "2.059e+02\n",
            "2.059e+02\n",
            "2.059e+02\n",
            "2.058e+02\n",
            "2.058e+02\n",
            "2.058e+02\n",
            "2.058e+02\n",
            "2.058e+02\n",
            "2.058e+02\n",
            "2.058e+02\n",
            "2.058e+02\n",
            "2.057e+02\n",
            "2.057e+02\n",
            "2.057e+02\n",
            "2.056e+02\n",
            "2.056e+02\n",
            "2.055e+02\n",
            "2.055e+02\n",
            "2.055e+02\n",
            "2.055e+02\n",
            "2.055e+02\n",
            "2.055e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.054e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.053e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.052e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.051e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.050e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.049e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "2.048e+02\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 204.770844\n",
            "  Number of iterations: 1080\n",
            "  Number of functions evaluations: 1216\n",
            "160.93243837356567\n"
          ]
        }
      ],
      "source": [
        "class DeepvdP:\n",
        "    # Initialize the class\n",
        "    def __init__(self, x, t, layers):\n",
        "\n",
        "        self.lb = t.min(0)\n",
        "        self.ub = t.max(0)\n",
        "        \n",
        "        self.x = x\n",
        "        self.t = t\n",
        "        \n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NN\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
        "\n",
        "        self.x_control = 2 * tf.math.sin(self.t_tf)#5.00 *\n",
        "        self.x_dd_control = - 2 * tf.math.sin(self.t_tf) #5.00 *\n",
        "\n",
        "        self.x_pred, self.x_dd_pred, self.ICs = self.vdP(self.t_tf)\n",
        "\n",
        "        self.x_res = self.x_control - self.x_pred\n",
        "        self.x_dd_res = self.x_dd_control - self.x_dd_pred\n",
        "\n",
        "        self.control = self.x_res + self.x_dd_res\n",
        "\n",
        "        self.loss = 1 * tf.reduce_sum(tf.square(self.control)) + tf.reduce_sum(tf.square(self.ICs)) + \\\n",
        "        tf.reduce_sum(tf.square( self.x_tf - (self.x_pred) )) #+ \\* 2 | * 2 / 5\n",
        "                    \n",
        "\n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 200000,\n",
        "                                                                           'maxfun': 200000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0 * np.finfo(float).eps}) \n",
        "\n",
        "\n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "# ==============================================================================================\n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]\n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "   \n",
        "    def neural_net(self, t, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(t - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "# ==============================================================================================\n",
        "    def vdP(self, t):\n",
        "      x = self.neural_net(tf.concat([t],1), self.weights, self.biases)\n",
        "      # dx_t = dde.grad.jacobian(x, t, i=0)\n",
        "      # dx_tt = dde.grad.hessian(x, t, i=0)\n",
        "      dx_t = tf.compat.v1.gradients(x, t)\n",
        "      dx_tt = tf.compat.v1.gradients(dx_t, t)\n",
        "      # x_desire = tf.math.sin(t) #5 * \n",
        "      # x_dot_desire = tf.math.cos(t) #5 * \n",
        "      # x_ddot_desire = - tf.math.sin(t) #-5 * \n",
        "      # control = (x_desire - x) + (x_ddot_desire - dx_tt)\n",
        "      ICs = x[0] - 1# Initial condition: 1, 5, 10\n",
        "      return x, dx_tt, ICs\n",
        "# ==============================================================================================\n",
        "    def callback(self, loss): #, betta\n",
        "        print('%.3e' % (loss)) #, betta B: %.5f\n",
        "        return loss\n",
        "      \n",
        "    def train(self, nIter): \n",
        "\n",
        "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t}\n",
        "\n",
        "        # var_loss = tf.Variable(tf_dict)\n",
        "        # loss = lambda: (var_loss ** 2)/2.0 \n",
        "\n",
        "        self.sess.run(self.train_op_Adam, feed_dict = tf_dict)\n",
        "\n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict = tf_dict,\n",
        "                                fetches = [self.loss],\n",
        "                                loss_callback = self.callback)\n",
        "\n",
        "        # self.optimizer.minimize(self.loss)\n",
        "        # self.optimizer.minimize(self.loss, global_step=None, var_list=var_loss,\n",
        "    # aggregation_method=None, colocate_gradients_with_ops=False, name=None,\n",
        "    # grad_loss=None)\n",
        "\n",
        "        # (self.sess, feed_dict = tf_dict, fetches = [self.loss], loss_callback = self.callback)\n",
        "            \n",
        "# ==============================================================================================    \n",
        "    def predict(self, t_star):\n",
        "        \n",
        "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t}  \n",
        "        x_star = self.sess.run(self.x_pred, tf_dict)\n",
        "        \n",
        "        return x_star"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\": \n",
        "    \n",
        "    layers = [1, 30, 30, 30, 30, 30, 30, 1]#30, 30, 30, 30, \\\n",
        "                #  30, 30, 30, 30, 30, 30, 30, 30, 30, 30, \\\n",
        "                #  30, 30, 30, 30, 30, 30, 30, 30, 30, 30, \\\n",
        "                #  30, 30, 30, 30, 30, 30, 30, 30, 30, 30, \\\n",
        "                #  30, 30, 30, 30, 30, 30, 30, 30, 30, 30, \n",
        "    # Set NN Structure\n",
        "    \n",
        "    data = scipy.io.loadmat('train.mat')\n",
        "    t_obtain = data['t'] # \n",
        "    X_obtain = data['x'] # \n",
        "    t_star = t_obtain[0:3000]\n",
        "    # t_star = t_star \n",
        "    X_star = X_obtain[0:3000]\n",
        "    # print(sol.t)\n",
        "    # print(sol.y[0])\n",
        "    N = X_star.shape[0]\n",
        "    T = t_star.shape[0]\n",
        "    # print(X_star)\n",
        "    # print(t_star)\n",
        "    # Rearrange Data \n",
        "    XX = np.tile(X_star, (1,T)) # [0:3000]\n",
        "    TT = np.tile(t_star, (1,N)).T # \n",
        "    \n",
        "    x = XX.flatten()[:,None] #\n",
        "    t = TT.flatten()[:,None] #\n",
        "\n",
        "    # Training Data    \n",
        "    x_train = X_star #x[:,:] # [idx,:]\n",
        "    # noise = 0.00\n",
        "    # x_train = x_train * (1 + noise*np.random.standard_normal(3000))\n",
        "    t_train = t_star #t[:,:]\n",
        "\n",
        "    # Training\n",
        "    t_tic = time.time()\n",
        "    model = DeepvdP(x_train, t_train, layers)\n",
        "    model.train(200000)\n",
        "    # cpu_time = timeit.default_timer()\n",
        "    # Prediction\n",
        "    x_pred = model.predict(t_star)\n",
        "    # loss_hist = model.callback()\n",
        "    elapsed_toc = time.time() - t_tic\n",
        "\n",
        "    np.savetxt(\"prediction.txt\", np.hstack(x_pred))\n",
        "    print(elapsed_toc)"
      ],
      "metadata": {
        "id": "-DJbwy8kaR5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "vanderPol_Fig4_benchmark.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkmfc4VTctKCWVyE7Gjrcg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}