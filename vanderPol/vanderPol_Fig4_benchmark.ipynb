{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanfengzhai/PIDOC/blob/main/vanderPol/vanderPol_Fig4_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yv3cUue4Ieq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cee7e67-b0b4-4b26-c9e8-c1058a277721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.0\n",
            "Uninstalling tensorflow-2.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.8.0\n",
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.21.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.13.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 49.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.43.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=b192539ce65e5c1b88a6b79fdc8f61c12d290ab0836832e4ea09eb3ece3a5c4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "1.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall tensorflow==2.8.0\n",
        "!pip install tensorflow==1.15.0\n",
        "import tensorflow as tf\n",
        "# import deepxde as dde\n",
        "import numpy as np\n",
        "from scipy import linspace\n",
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "import time\n",
        "import timeit\n",
        "# import tensorflow_probability as tfp\n",
        "\n",
        "# tf.disable_v2_behavior()\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gvqAyqq3IwUF"
      },
      "outputs": [],
      "source": [
        "class DeepvdP:\n",
        "    # Initialize the class\n",
        "    def __init__(self, x, t, layers):\n",
        "\n",
        "        self.lb = t.min(0)\n",
        "        self.ub = t.max(0)\n",
        "        \n",
        "        self.x = x\n",
        "        self.t = t\n",
        "        \n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NN\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
        "\n",
        "        self.x_control = 2 * tf.math.sin(self.t_tf)#5.00 *\n",
        "        self.x_dd_control = - 2 * tf.math.sin(self.t_tf) #5.00 *\n",
        "\n",
        "        self.x_pred, self.x_dd_pred, self.ICs = self.vdP(self.t_tf)\n",
        "\n",
        "        self.x_res = self.x_control - self.x_pred\n",
        "        self.x_dd_res = self.x_dd_control - self.x_dd_pred\n",
        "\n",
        "        self.control = self.x_res + self.x_dd_res\n",
        "\n",
        "        self.loss = 1 * tf.reduce_sum(tf.square(self.control)) + tf.reduce_sum(tf.square(self.ICs)) + \\\n",
        "        tf.reduce_sum(tf.square( self.x_tf - (self.x_pred) )) #+ \\* 2 | * 2 / 5\n",
        "                    \n",
        "\n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 200000,\n",
        "                                                                           'maxfun': 200000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0 * np.finfo(float).eps}) \n",
        "\n",
        "\n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "# ==============================================================================================\n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]\n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "   \n",
        "    def neural_net(self, t, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(t - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "# ==============================================================================================\n",
        "    def vdP(self, t):\n",
        "      x = self.neural_net(tf.concat([t],1), self.weights, self.biases)\n",
        "      # dx_t = dde.grad.jacobian(x, t, i=0)\n",
        "      # dx_tt = dde.grad.hessian(x, t, i=0)\n",
        "      dx_t = tf.compat.v1.gradients(x, t)\n",
        "      dx_tt = tf.compat.v1.gradients(dx_t, t)\n",
        "      # x_desire = tf.math.sin(t) #5 * \n",
        "      # x_dot_desire = tf.math.cos(t) #5 * \n",
        "      # x_ddot_desire = - tf.math.sin(t) #-5 * \n",
        "      # control = (x_desire - x) + (x_ddot_desire - dx_tt)\n",
        "      ICs = x[0] - 1# Initial condition: 1, 5, 10\n",
        "      return x, dx_tt, ICs\n",
        "# ==============================================================================================\n",
        "    def callback(self, loss): #, betta\n",
        "        print('%.3e' % (loss)) #, betta B: %.5f\n",
        "        return loss\n",
        "      \n",
        "    def train(self, nIter): \n",
        "\n",
        "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t}\n",
        "\n",
        "        # var_loss = tf.Variable(tf_dict)\n",
        "        # loss = lambda: (var_loss ** 2)/2.0 \n",
        "\n",
        "        self.sess.run(self.train_op_Adam, feed_dict = tf_dict)\n",
        "\n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict = tf_dict,\n",
        "                                fetches = [self.loss],\n",
        "                                loss_callback = self.callback)\n",
        "\n",
        "        # self.optimizer.minimize(self.loss)\n",
        "        # self.optimizer.minimize(self.loss, global_step=None, var_list=var_loss,\n",
        "    # aggregation_method=None, colocate_gradients_with_ops=False, name=None,\n",
        "    # grad_loss=None)\n",
        "\n",
        "        # (self.sess, feed_dict = tf_dict, fetches = [self.loss], loss_callback = self.callback)\n",
        "            \n",
        "# ==============================================================================================    \n",
        "    def predict(self, t_star):\n",
        "        \n",
        "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t}  \n",
        "        x_star = self.sess.run(self.x_pred, tf_dict)\n",
        "        \n",
        "        return x_star"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\": \n",
        "    \n",
        "    layers = [1, 30, 30, 30, 30, 30, 30, 1]#30, 30, 30, 30, \\\n",
        "                #  30, 30, 30, 30, 30, 30, 30, 30, 30, 30, \\\n",
        "                #  30, 30, 30, 30, 30, 30, 30, 30, 30, 30, \\\n",
        "                #  30, 30, 30, 30, 30, 30, 30, 30, 30, 30, \\\n",
        "                #  30, 30, 30, 30, 30, 30, 30, 30, 30, 30, \n",
        "    # Set NN Structure\n",
        "    \n",
        "    data = scipy.io.loadmat('train.mat')\n",
        "    t_obtain = data['t'] # \n",
        "    X_obtain = data['x'] # \n",
        "    t_star = t_obtain[0:3000]\n",
        "    # t_star = t_star \n",
        "    X_star = X_obtain[0:3000]\n",
        "    # print(sol.t)\n",
        "    # print(sol.y[0])\n",
        "    N = X_star.shape[0]\n",
        "    T = t_star.shape[0]\n",
        "    # print(X_star)\n",
        "    # print(t_star)\n",
        "    # Rearrange Data \n",
        "    XX = np.tile(X_star, (1,T)) # [0:3000]\n",
        "    TT = np.tile(t_star, (1,N)).T # \n",
        "    \n",
        "    x = XX.flatten()[:,None] #\n",
        "    t = TT.flatten()[:,None] #\n",
        "\n",
        "    # Training Data    \n",
        "    x_train = X_star #x[:,:] # [idx,:]\n",
        "    # noise = 0.00\n",
        "    # x_train = x_train * (1 + noise*np.random.standard_normal(3000))\n",
        "    t_train = t_star #t[:,:]\n",
        "\n",
        "    # Training\n",
        "    t_tic = time.time()\n",
        "    model = DeepvdP(x_train, t_train, layers)\n",
        "    model.train(200000)\n",
        "    # cpu_time = timeit.default_timer()\n",
        "    # Prediction\n",
        "    x_pred = model.predict(t_star)\n",
        "    # loss_hist = model.callback()\n",
        "    elapsed_toc = time.time() - t_tic\n",
        "\n",
        "    np.savetxt(\"prediction.txt\", np.hstack(x_pred))\n",
        "    print(elapsed_toc)"
      ],
      "metadata": {
        "id": "-DJbwy8kaR5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62586b9-e2f5-4636-f039-11550f511f36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "5.952e+03\n",
            "7.755e+03\n",
            "5.951e+03\n",
            "5.949e+03\n",
            "5.948e+03\n",
            "5.948e+03\n",
            "5.948e+03\n",
            "5.948e+03\n",
            "5.947e+03\n",
            "5.946e+03\n",
            "5.942e+03\n",
            "5.943e+03\n",
            "5.941e+03\n",
            "5.941e+03\n",
            "5.940e+03\n",
            "5.936e+03\n",
            "5.935e+03\n",
            "5.935e+03\n",
            "5.933e+03\n",
            "5.931e+03\n",
            "5.929e+03\n",
            "5.929e+03\n",
            "5.929e+03\n",
            "5.928e+03\n",
            "5.927e+03\n",
            "5.926e+03\n",
            "5.945e+03\n",
            "5.925e+03\n",
            "5.925e+03\n",
            "5.925e+03\n",
            "5.924e+03\n",
            "5.938e+03\n",
            "5.923e+03\n",
            "5.927e+03\n",
            "5.922e+03\n",
            "5.922e+03\n",
            "5.922e+03\n",
            "5.921e+03\n",
            "5.920e+03\n",
            "5.919e+03\n",
            "5.918e+03\n",
            "5.927e+03\n",
            "5.917e+03\n",
            "5.916e+03\n",
            "5.916e+03\n",
            "5.915e+03\n",
            "5.914e+03\n",
            "5.914e+03\n",
            "7.567e+03\n",
            "5.914e+03\n",
            "5.914e+03\n",
            "6.126e+03\n",
            "5.913e+03\n",
            "6.863e+03\n",
            "5.913e+03\n",
            "5.913e+03\n",
            "5.912e+03\n",
            "5.912e+03\n",
            "5.912e+03\n",
            "5.911e+03\n",
            "5.909e+03\n",
            "5.955e+03\n",
            "5.908e+03\n",
            "5.907e+03\n",
            "5.907e+03\n",
            "5.906e+03\n",
            "5.906e+03\n",
            "5.906e+03\n",
            "5.905e+03\n",
            "5.902e+03\n",
            "5.918e+03\n",
            "5.900e+03\n",
            "5.896e+03\n",
            "5.891e+03\n",
            "5.886e+03\n",
            "5.870e+03\n",
            "5.883e+03\n",
            "5.861e+03\n",
            "5.881e+03\n",
            "5.857e+03\n",
            "5.856e+03\n",
            "5.854e+03\n",
            "5.851e+03\n",
            "5.843e+03\n",
            "7.430e+03\n",
            "5.834e+03\n",
            "5.843e+03\n",
            "5.828e+03\n",
            "5.823e+03\n",
            "5.821e+03\n",
            "5.812e+03\n",
            "5.787e+03\n",
            "5.556e+03\n",
            "3.594e+04\n",
            "5.481e+03\n",
            "5.409e+03\n",
            "7.234e+03\n",
            "5.324e+03\n",
            "2.294e+12\n",
            "3.594e+07\n",
            "5.324e+03\n",
            "5.321e+03\n",
            "7.123e+03\n",
            "5.214e+03\n",
            "5.627e+04\n",
            "5.186e+03\n",
            "5.351e+03\n",
            "5.138e+03\n",
            "5.174e+03\n",
            "5.075e+03\n",
            "5.065e+03\n",
            "5.027e+03\n",
            "5.024e+03\n",
            "5.007e+03\n",
            "4.982e+03\n",
            "4.951e+03\n",
            "4.918e+03\n",
            "4.894e+03\n",
            "4.884e+03\n",
            "4.858e+03\n",
            "4.825e+03\n",
            "4.765e+03\n",
            "4.720e+03\n",
            "4.651e+03\n",
            "4.604e+03\n",
            "4.654e+03\n",
            "4.565e+03\n",
            "4.537e+03\n",
            "4.514e+03\n",
            "4.499e+03\n",
            "4.491e+03\n",
            "4.478e+03\n",
            "4.425e+03\n",
            "4.377e+03\n",
            "4.374e+03\n",
            "4.340e+03\n",
            "4.291e+03\n",
            "4.266e+03\n",
            "4.247e+03\n",
            "4.239e+03\n",
            "4.229e+03\n",
            "4.209e+03\n",
            "4.190e+03\n",
            "4.130e+03\n",
            "4.081e+03\n",
            "4.016e+03\n",
            "3.951e+03\n",
            "3.931e+03\n",
            "3.913e+03\n",
            "3.888e+03\n",
            "3.877e+03\n",
            "3.865e+03\n",
            "3.853e+03\n",
            "3.818e+03\n",
            "3.783e+03\n",
            "3.763e+03\n",
            "3.724e+03\n",
            "3.689e+03\n",
            "3.627e+03\n",
            "3.587e+03\n",
            "3.549e+03\n",
            "3.550e+03\n",
            "3.517e+03\n",
            "3.675e+03\n",
            "3.499e+03\n",
            "3.492e+03\n",
            "3.474e+03\n",
            "3.451e+03\n",
            "3.432e+03\n",
            "3.407e+03\n",
            "3.380e+03\n",
            "3.334e+03\n",
            "3.299e+03\n",
            "3.281e+03\n",
            "3.249e+03\n",
            "3.220e+03\n",
            "3.189e+03\n",
            "3.153e+03\n",
            "3.117e+03\n",
            "3.074e+03\n",
            "3.056e+03\n",
            "3.045e+03\n",
            "3.036e+03\n",
            "3.032e+03\n",
            "3.026e+03\n",
            "3.013e+03\n",
            "3.000e+03\n",
            "2.978e+03\n",
            "2.954e+03\n",
            "2.922e+03\n",
            "2.908e+03\n",
            "2.850e+03\n",
            "2.831e+03\n",
            "2.783e+03\n",
            "2.756e+03\n",
            "2.726e+03\n",
            "2.740e+03\n",
            "2.709e+03\n",
            "2.691e+03\n",
            "2.680e+03\n",
            "2.664e+03\n",
            "2.652e+03\n",
            "2.645e+03\n",
            "2.638e+03\n",
            "2.616e+03\n",
            "2.592e+03\n",
            "2.560e+03\n",
            "2.522e+03\n",
            "2.501e+03\n",
            "2.487e+03\n",
            "2.466e+03\n",
            "2.448e+03\n",
            "2.427e+03\n",
            "2.419e+03\n",
            "2.411e+03\n",
            "2.397e+03\n",
            "2.385e+03\n",
            "2.378e+03\n",
            "2.372e+03\n",
            "2.365e+03\n",
            "2.358e+03\n",
            "2.351e+03\n",
            "2.340e+03\n",
            "2.320e+03\n",
            "2.383e+03\n",
            "2.312e+03\n",
            "2.296e+03\n",
            "2.260e+03\n",
            "2.249e+03\n",
            "2.233e+03\n",
            "2.227e+03\n",
            "2.222e+03\n",
            "2.217e+03\n",
            "2.207e+03\n",
            "2.192e+03\n",
            "2.164e+03\n",
            "2.130e+03\n",
            "2.115e+03\n",
            "2.093e+03\n",
            "2.077e+03\n",
            "2.061e+03\n",
            "2.044e+03\n",
            "2.040e+03\n",
            "2.035e+03\n",
            "2.026e+03\n",
            "2.018e+03\n",
            "2.012e+03\n",
            "2.003e+03\n",
            "1.993e+03\n",
            "1.979e+03\n",
            "1.960e+03\n",
            "1.951e+03\n",
            "1.947e+03\n",
            "1.939e+03\n",
            "1.935e+03\n",
            "1.929e+03\n",
            "1.921e+03\n",
            "1.912e+03\n",
            "1.901e+03\n",
            "1.899e+03\n",
            "1.889e+03\n",
            "1.884e+03\n",
            "1.878e+03\n",
            "1.874e+03\n",
            "1.869e+03\n",
            "1.862e+03\n",
            "1.851e+03\n",
            "1.832e+03\n",
            "1.800e+03\n",
            "1.772e+03\n",
            "1.772e+03\n",
            "1.758e+03\n",
            "1.788e+03\n",
            "1.741e+03\n",
            "1.735e+03\n",
            "1.724e+03\n",
            "1.718e+03\n",
            "1.712e+03\n",
            "1.707e+03\n",
            "1.703e+03\n",
            "1.701e+03\n",
            "1.697e+03\n",
            "1.689e+03\n",
            "1.682e+03\n",
            "1.674e+03\n",
            "1.670e+03\n",
            "1.667e+03\n",
            "1.664e+03\n",
            "1.656e+03\n",
            "1.648e+03\n",
            "1.642e+03\n",
            "1.637e+03\n",
            "1.633e+03\n",
            "1.629e+03\n",
            "1.614e+03\n",
            "1.592e+03\n",
            "1.569e+03\n",
            "1.538e+03\n",
            "1.516e+03\n",
            "1.504e+03\n",
            "1.491e+03\n",
            "1.487e+03\n",
            "1.474e+03\n",
            "1.457e+03\n",
            "1.444e+03\n",
            "1.435e+03\n",
            "1.422e+03\n",
            "1.416e+03\n",
            "1.405e+03\n",
            "1.380e+03\n",
            "1.387e+03\n",
            "1.361e+03\n",
            "1.349e+03\n",
            "1.333e+03\n",
            "1.340e+03\n",
            "1.323e+03\n",
            "1.316e+03\n",
            "1.300e+03\n",
            "1.292e+03\n",
            "1.287e+03\n",
            "1.277e+03\n",
            "1.258e+03\n",
            "1.244e+03\n",
            "1.234e+03\n",
            "1.228e+03\n",
            "1.219e+03\n",
            "1.199e+03\n",
            "1.177e+03\n",
            "1.146e+03\n",
            "1.133e+03\n",
            "1.135e+03\n",
            "1.123e+03\n",
            "1.115e+03\n",
            "1.105e+03\n",
            "1.103e+03\n",
            "1.095e+03\n",
            "1.096e+03\n",
            "1.094e+03\n",
            "1.092e+03\n",
            "1.090e+03\n",
            "1.087e+03\n",
            "1.083e+03\n",
            "1.079e+03\n",
            "1.074e+03\n",
            "1.070e+03\n",
            "1.064e+03\n",
            "1.057e+03\n",
            "1.052e+03\n",
            "1.032e+03\n",
            "1.023e+03\n",
            "1.015e+03\n",
            "1.012e+03\n",
            "1.008e+03\n",
            "1.006e+03\n",
            "1.002e+03\n",
            "9.968e+02\n",
            "9.930e+02\n",
            "9.881e+02\n",
            "9.859e+02\n",
            "9.866e+02\n",
            "9.836e+02\n",
            "9.833e+02\n",
            "9.809e+02\n",
            "9.787e+02\n",
            "9.746e+02\n",
            "9.716e+02\n",
            "9.677e+02\n",
            "9.626e+02\n",
            "9.579e+02\n",
            "9.556e+02\n",
            "9.541e+02\n",
            "9.520e+02\n",
            "9.496e+02\n",
            "9.471e+02\n",
            "9.435e+02\n",
            "9.390e+02\n",
            "9.347e+02\n",
            "9.300e+02\n",
            "9.254e+02\n",
            "9.206e+02\n",
            "9.177e+02\n",
            "9.152e+02\n",
            "9.137e+02\n",
            "9.119e+02\n",
            "9.099e+02\n",
            "9.080e+02\n",
            "9.050e+02\n",
            "9.063e+02\n",
            "9.035e+02\n",
            "9.010e+02\n",
            "8.974e+02\n",
            "8.953e+02\n",
            "8.913e+02\n",
            "8.877e+02\n",
            "8.847e+02\n",
            "8.819e+02\n",
            "8.775e+02\n",
            "8.741e+02\n",
            "8.720e+02\n",
            "8.714e+02\n",
            "8.711e+02\n",
            "8.706e+02\n",
            "8.701e+02\n",
            "8.689e+02\n",
            "8.662e+02\n",
            "8.662e+02\n",
            "8.648e+02\n",
            "8.618e+02\n",
            "8.596e+02\n",
            "8.569e+02\n",
            "8.537e+02\n",
            "8.497e+02\n",
            "8.536e+02\n",
            "8.479e+02\n",
            "8.459e+02\n",
            "8.438e+02\n",
            "8.416e+02\n",
            "8.381e+02\n",
            "8.328e+02\n",
            "8.286e+02\n",
            "8.232e+02\n",
            "8.195e+02\n",
            "8.171e+02\n",
            "8.153e+02\n",
            "8.105e+02\n",
            "8.031e+02\n",
            "7.934e+02\n",
            "7.824e+02\n",
            "7.882e+02\n",
            "7.764e+02\n",
            "7.771e+02\n",
            "7.658e+02\n",
            "7.575e+02\n",
            "7.489e+02\n",
            "7.412e+02\n",
            "7.335e+02\n",
            "7.215e+02\n",
            "7.046e+02\n",
            "6.930e+02\n",
            "6.840e+02\n",
            "6.719e+02\n",
            "6.589e+02\n",
            "6.506e+02\n",
            "6.432e+02\n",
            "6.363e+02\n",
            "6.270e+02\n",
            "6.149e+02\n",
            "5.961e+02\n",
            "5.753e+02\n",
            "5.515e+02\n",
            "5.387e+02\n",
            "5.173e+02\n",
            "5.108e+02\n",
            "5.032e+02\n",
            "4.918e+02\n",
            "4.600e+02\n",
            "4.464e+02\n",
            "4.158e+02\n",
            "3.908e+02\n",
            "3.718e+02\n",
            "3.544e+02\n",
            "3.540e+02\n",
            "3.451e+02\n",
            "3.322e+02\n",
            "3.166e+02\n",
            "3.015e+02\n",
            "2.893e+02\n",
            "2.765e+02\n",
            "2.668e+02\n",
            "2.623e+02\n",
            "2.563e+02\n",
            "2.498e+02\n",
            "2.443e+02\n",
            "2.372e+02\n",
            "2.311e+02\n",
            "2.260e+02\n",
            "2.213e+02\n",
            "2.193e+02\n",
            "2.183e+02\n",
            "2.172e+02\n",
            "2.165e+02\n",
            "2.149e+02\n",
            "2.130e+02\n",
            "2.101e+02\n",
            "2.079e+02\n",
            "2.059e+02\n",
            "2.039e+02\n",
            "2.021e+02\n",
            "2.006e+02\n",
            "1.996e+02\n",
            "1.984e+02\n",
            "1.967e+02\n",
            "1.947e+02\n",
            "1.923e+02\n",
            "1.907e+02\n",
            "1.891e+02\n",
            "1.884e+02\n",
            "1.879e+02\n",
            "1.875e+02\n",
            "1.872e+02\n",
            "1.868e+02\n",
            "1.866e+02\n",
            "1.864e+02\n",
            "1.863e+02\n",
            "1.862e+02\n",
            "1.860e+02\n",
            "1.857e+02\n",
            "1.855e+02\n",
            "1.846e+02\n",
            "1.838e+02\n",
            "1.827e+02\n",
            "1.818e+02\n",
            "1.822e+02\n",
            "1.815e+02\n",
            "1.808e+02\n",
            "1.804e+02\n",
            "1.798e+02\n",
            "1.794e+02\n",
            "1.792e+02\n",
            "1.789e+02\n",
            "1.801e+02\n",
            "1.788e+02\n",
            "1.784e+02\n",
            "1.782e+02\n",
            "1.779e+02\n",
            "1.777e+02\n",
            "1.775e+02\n",
            "1.772e+02\n",
            "1.771e+02\n",
            "1.769e+02\n",
            "1.767e+02\n",
            "1.766e+02\n",
            "1.765e+02\n",
            "1.763e+02\n",
            "1.763e+02\n",
            "1.761e+02\n",
            "1.760e+02\n",
            "1.759e+02\n",
            "1.757e+02\n",
            "1.756e+02\n",
            "1.753e+02\n",
            "1.800e+02\n",
            "1.752e+02\n",
            "1.749e+02\n",
            "1.742e+02\n",
            "1.736e+02\n",
            "1.733e+02\n",
            "1.731e+02\n",
            "1.730e+02\n",
            "1.730e+02\n",
            "1.730e+02\n",
            "1.729e+02\n",
            "1.728e+02\n",
            "1.729e+02\n",
            "1.728e+02\n",
            "1.727e+02\n",
            "1.726e+02\n",
            "1.725e+02\n",
            "1.724e+02\n",
            "1.724e+02\n",
            "1.723e+02\n",
            "1.722e+02\n",
            "1.721e+02\n",
            "1.721e+02\n",
            "1.720e+02\n",
            "1.718e+02\n",
            "1.716e+02\n",
            "1.713e+02\n",
            "1.710e+02\n",
            "1.708e+02\n",
            "1.707e+02\n",
            "1.705e+02\n",
            "1.703e+02\n",
            "1.703e+02\n",
            "1.703e+02\n",
            "1.702e+02\n",
            "1.702e+02\n",
            "1.701e+02\n",
            "1.701e+02\n",
            "1.700e+02\n",
            "1.702e+02\n",
            "1.699e+02\n",
            "1.697e+02\n",
            "1.789e+02\n",
            "1.696e+02\n",
            "1.731e+02\n",
            "1.694e+02\n",
            "1.689e+02\n",
            "1.698e+02\n",
            "1.685e+02\n",
            "1.683e+02\n",
            "1.682e+02\n",
            "1.684e+02\n",
            "1.681e+02\n",
            "1.680e+02\n",
            "1.680e+02\n",
            "1.679e+02\n",
            "1.679e+02\n",
            "1.678e+02\n",
            "1.678e+02\n",
            "1.678e+02\n",
            "1.677e+02\n",
            "1.677e+02\n",
            "1.677e+02\n",
            "1.676e+02\n",
            "1.676e+02\n",
            "1.675e+02\n",
            "1.673e+02\n",
            "1.673e+02\n",
            "1.670e+02\n",
            "1.669e+02\n",
            "1.667e+02\n",
            "1.666e+02\n",
            "1.665e+02\n",
            "1.665e+02\n",
            "1.664e+02\n",
            "1.664e+02\n",
            "1.663e+02\n",
            "1.662e+02\n",
            "1.661e+02\n",
            "1.662e+02\n",
            "1.661e+02\n",
            "1.660e+02\n",
            "1.659e+02\n",
            "1.657e+02\n",
            "1.656e+02\n",
            "1.655e+02\n",
            "1.654e+02\n",
            "1.654e+02\n",
            "1.653e+02\n",
            "1.653e+02\n",
            "1.652e+02\n",
            "1.652e+02\n",
            "1.651e+02\n",
            "1.651e+02\n",
            "1.650e+02\n",
            "1.649e+02\n",
            "1.648e+02\n",
            "1.647e+02\n",
            "1.647e+02\n",
            "1.647e+02\n",
            "1.646e+02\n",
            "1.646e+02\n",
            "1.645e+02\n",
            "1.643e+02\n",
            "1.642e+02\n",
            "1.641e+02\n",
            "1.640e+02\n",
            "1.641e+02\n",
            "1.640e+02\n",
            "1.640e+02\n",
            "1.639e+02\n",
            "1.639e+02\n",
            "1.638e+02\n",
            "1.638e+02\n",
            "1.640e+02\n",
            "1.638e+02\n",
            "1.638e+02\n",
            "1.638e+02\n",
            "1.638e+02\n",
            "1.637e+02\n",
            "1.637e+02\n",
            "1.637e+02\n",
            "1.637e+02\n",
            "1.637e+02\n",
            "1.637e+02\n",
            "1.636e+02\n",
            "1.636e+02\n",
            "1.637e+02\n",
            "1.636e+02\n",
            "1.635e+02\n",
            "1.635e+02\n",
            "1.635e+02\n",
            "1.635e+02\n",
            "1.634e+02\n",
            "1.634e+02\n",
            "1.634e+02\n",
            "1.633e+02\n",
            "1.633e+02\n",
            "1.633e+02\n",
            "1.632e+02\n",
            "1.632e+02\n",
            "1.632e+02\n",
            "1.631e+02\n",
            "1.631e+02\n",
            "1.631e+02\n",
            "1.631e+02\n",
            "1.631e+02\n",
            "1.631e+02\n",
            "1.631e+02\n",
            "1.630e+02\n",
            "1.630e+02\n",
            "1.630e+02\n",
            "1.630e+02\n",
            "1.630e+02\n",
            "1.631e+02\n",
            "1.630e+02\n",
            "1.630e+02\n",
            "1.630e+02\n",
            "1.630e+02\n",
            "1.629e+02\n",
            "1.629e+02\n",
            "1.629e+02\n",
            "1.629e+02\n",
            "1.629e+02\n",
            "1.629e+02\n",
            "1.629e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.629e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.628e+02\n",
            "1.627e+02\n",
            "1.627e+02\n",
            "1.627e+02\n",
            "1.627e+02\n",
            "1.627e+02\n",
            "1.627e+02\n",
            "1.627e+02\n",
            "1.627e+02\n",
            "1.627e+02\n",
            "1.627e+02\n",
            "1.626e+02\n",
            "1.626e+02\n",
            "1.625e+02\n",
            "1.624e+02\n",
            "1.623e+02\n",
            "1.623e+02\n",
            "1.622e+02\n",
            "1.622e+02\n",
            "1.622e+02\n",
            "1.627e+02\n",
            "1.622e+02\n",
            "1.622e+02\n",
            "1.621e+02\n",
            "1.621e+02\n",
            "1.621e+02\n",
            "1.621e+02\n",
            "1.621e+02\n",
            "1.621e+02\n",
            "1.621e+02\n",
            "1.620e+02\n",
            "1.620e+02\n",
            "1.620e+02\n",
            "1.620e+02\n",
            "1.620e+02\n",
            "1.620e+02\n",
            "1.620e+02\n",
            "1.620e+02\n",
            "1.620e+02\n",
            "1.621e+02\n",
            "1.620e+02\n",
            "1.619e+02\n",
            "1.619e+02\n",
            "1.619e+02\n",
            "1.619e+02\n",
            "1.619e+02\n",
            "1.618e+02\n",
            "1.619e+02\n",
            "1.618e+02\n",
            "1.618e+02\n",
            "1.618e+02\n",
            "1.618e+02\n",
            "1.618e+02\n",
            "1.617e+02\n",
            "1.617e+02\n",
            "1.617e+02\n",
            "1.618e+02\n",
            "1.617e+02\n",
            "1.616e+02\n",
            "1.616e+02\n",
            "1.616e+02\n",
            "1.615e+02\n",
            "1.615e+02\n",
            "1.615e+02\n",
            "1.615e+02\n",
            "1.615e+02\n",
            "1.615e+02\n",
            "1.614e+02\n",
            "1.614e+02\n",
            "1.614e+02\n",
            "1.614e+02\n",
            "1.613e+02\n",
            "1.613e+02\n",
            "1.613e+02\n",
            "1.613e+02\n",
            "1.613e+02\n",
            "1.613e+02\n",
            "1.612e+02\n",
            "1.612e+02\n",
            "1.612e+02\n",
            "1.612e+02\n",
            "1.612e+02\n",
            "1.611e+02\n",
            "1.611e+02\n",
            "1.611e+02\n",
            "1.611e+02\n",
            "1.610e+02\n",
            "1.610e+02\n",
            "1.610e+02\n",
            "1.610e+02\n",
            "1.610e+02\n",
            "1.609e+02\n",
            "1.609e+02\n",
            "1.608e+02\n",
            "1.608e+02\n",
            "1.607e+02\n",
            "1.607e+02\n",
            "1.607e+02\n",
            "1.607e+02\n",
            "1.607e+02\n",
            "1.606e+02\n",
            "1.606e+02\n",
            "1.605e+02\n",
            "1.605e+02\n",
            "1.619e+02\n",
            "1.604e+02\n",
            "1.604e+02\n",
            "1.603e+02\n",
            "1.603e+02\n",
            "1.603e+02\n",
            "1.602e+02\n",
            "1.602e+02\n",
            "1.601e+02\n",
            "1.601e+02\n",
            "1.600e+02\n",
            "1.600e+02\n",
            "1.600e+02\n",
            "1.599e+02\n",
            "1.599e+02\n",
            "1.598e+02\n",
            "1.598e+02\n",
            "1.597e+02\n",
            "1.597e+02\n",
            "1.596e+02\n",
            "1.596e+02\n",
            "1.595e+02\n",
            "1.594e+02\n",
            "1.594e+02\n",
            "1.593e+02\n",
            "1.592e+02\n",
            "1.591e+02\n",
            "1.592e+02\n",
            "1.591e+02\n",
            "1.591e+02\n",
            "1.591e+02\n",
            "1.591e+02\n",
            "1.590e+02\n",
            "1.590e+02\n",
            "1.590e+02\n",
            "1.590e+02\n",
            "1.589e+02\n",
            "1.589e+02\n",
            "1.589e+02\n",
            "1.589e+02\n",
            "1.588e+02\n",
            "1.588e+02\n",
            "1.587e+02\n",
            "1.586e+02\n",
            "1.585e+02\n",
            "1.584e+02\n",
            "1.583e+02\n",
            "1.582e+02\n",
            "1.582e+02\n",
            "1.581e+02\n",
            "1.580e+02\n",
            "1.580e+02\n",
            "1.579e+02\n",
            "1.578e+02\n",
            "1.576e+02\n",
            "1.575e+02\n",
            "1.574e+02\n",
            "1.573e+02\n",
            "1.572e+02\n",
            "1.571e+02\n",
            "1.570e+02\n",
            "1.569e+02\n",
            "1.569e+02\n",
            "1.567e+02\n",
            "1.566e+02\n",
            "1.565e+02\n",
            "1.566e+02\n",
            "1.564e+02\n",
            "1.562e+02\n",
            "1.561e+02\n",
            "1.560e+02\n",
            "1.559e+02\n",
            "1.559e+02\n",
            "1.558e+02\n",
            "1.557e+02\n",
            "1.556e+02\n",
            "1.555e+02\n",
            "1.554e+02\n",
            "1.554e+02\n",
            "1.553e+02\n",
            "1.553e+02\n",
            "1.552e+02\n",
            "1.552e+02\n",
            "1.552e+02\n",
            "1.552e+02\n",
            "1.551e+02\n",
            "1.551e+02\n",
            "1.551e+02\n",
            "1.551e+02\n",
            "1.551e+02\n",
            "1.550e+02\n",
            "1.548e+02\n",
            "1.548e+02\n",
            "1.561e+02\n",
            "1.547e+02\n",
            "1.546e+02\n",
            "1.545e+02\n",
            "1.545e+02\n",
            "1.544e+02\n",
            "1.542e+02\n",
            "1.538e+02\n",
            "1.535e+02\n",
            "1.535e+02\n",
            "1.533e+02\n",
            "1.534e+02\n",
            "1.532e+02\n",
            "1.531e+02\n",
            "1.531e+02\n",
            "1.531e+02\n",
            "1.530e+02\n",
            "1.530e+02\n",
            "1.530e+02\n",
            "1.529e+02\n",
            "1.529e+02\n",
            "1.532e+02\n",
            "1.529e+02\n",
            "1.529e+02\n",
            "1.528e+02\n",
            "1.528e+02\n",
            "1.527e+02\n",
            "1.526e+02\n",
            "1.525e+02\n",
            "1.524e+02\n",
            "1.523e+02\n",
            "1.521e+02\n",
            "1.520e+02\n",
            "1.519e+02\n",
            "1.518e+02\n",
            "1.518e+02\n",
            "1.517e+02\n",
            "1.516e+02\n",
            "1.515e+02\n",
            "1.515e+02\n",
            "1.514e+02\n",
            "1.514e+02\n",
            "1.514e+02\n",
            "1.514e+02\n",
            "1.513e+02\n",
            "1.513e+02\n",
            "1.514e+02\n",
            "1.512e+02\n",
            "1.512e+02\n",
            "1.511e+02\n",
            "1.510e+02\n",
            "1.509e+02\n",
            "1.509e+02\n",
            "1.508e+02\n",
            "1.508e+02\n",
            "1.508e+02\n",
            "1.508e+02\n",
            "1.507e+02\n",
            "1.507e+02\n",
            "1.506e+02\n",
            "1.506e+02\n",
            "1.504e+02\n",
            "1.503e+02\n",
            "1.500e+02\n",
            "1.498e+02\n",
            "1.497e+02\n",
            "1.497e+02\n",
            "1.496e+02\n",
            "1.495e+02\n",
            "1.495e+02\n",
            "1.494e+02\n",
            "1.493e+02\n",
            "1.493e+02\n",
            "1.491e+02\n",
            "1.490e+02\n",
            "1.490e+02\n",
            "1.489e+02\n",
            "1.488e+02\n",
            "1.487e+02\n",
            "1.486e+02\n",
            "1.486e+02\n",
            "1.485e+02\n",
            "1.485e+02\n",
            "1.485e+02\n",
            "1.484e+02\n",
            "1.484e+02\n",
            "1.484e+02\n",
            "1.484e+02\n",
            "1.483e+02\n",
            "1.483e+02\n",
            "1.482e+02\n",
            "1.482e+02\n",
            "1.482e+02\n",
            "1.481e+02\n",
            "1.481e+02\n",
            "1.481e+02\n",
            "1.480e+02\n",
            "1.480e+02\n",
            "1.480e+02\n",
            "1.480e+02\n",
            "1.479e+02\n",
            "1.478e+02\n",
            "1.477e+02\n",
            "1.477e+02\n",
            "1.476e+02\n",
            "1.476e+02\n",
            "1.476e+02\n",
            "1.475e+02\n",
            "1.475e+02\n",
            "1.474e+02\n",
            "1.478e+02\n",
            "1.474e+02\n",
            "1.473e+02\n",
            "1.473e+02\n",
            "1.473e+02\n",
            "1.473e+02\n",
            "1.473e+02\n",
            "1.472e+02\n",
            "1.472e+02\n",
            "1.472e+02\n",
            "1.472e+02\n",
            "1.471e+02\n",
            "1.471e+02\n",
            "1.471e+02\n",
            "1.471e+02\n",
            "1.471e+02\n",
            "1.470e+02\n",
            "1.470e+02\n",
            "1.470e+02\n",
            "1.470e+02\n",
            "1.469e+02\n",
            "1.469e+02\n",
            "1.469e+02\n",
            "1.468e+02\n",
            "1.468e+02\n",
            "1.468e+02\n",
            "1.468e+02\n",
            "1.468e+02\n",
            "1.468e+02\n",
            "1.468e+02\n",
            "1.468e+02\n",
            "1.468e+02\n",
            "1.468e+02\n",
            "1.467e+02\n",
            "1.467e+02\n",
            "1.467e+02\n",
            "1.467e+02\n",
            "1.467e+02\n",
            "1.467e+02\n",
            "1.467e+02\n",
            "1.466e+02\n",
            "1.466e+02\n",
            "1.465e+02\n",
            "1.465e+02\n",
            "1.465e+02\n",
            "1.464e+02\n",
            "1.464e+02\n",
            "1.464e+02\n",
            "1.464e+02\n",
            "1.464e+02\n",
            "1.467e+02\n",
            "1.463e+02\n",
            "1.463e+02\n",
            "1.463e+02\n",
            "1.463e+02\n",
            "1.462e+02\n",
            "1.462e+02\n",
            "1.461e+02\n",
            "1.461e+02\n",
            "1.461e+02\n",
            "1.461e+02\n",
            "1.461e+02\n",
            "1.461e+02\n",
            "1.461e+02\n",
            "1.461e+02\n",
            "1.460e+02\n",
            "1.460e+02\n",
            "1.460e+02\n",
            "1.460e+02\n",
            "1.460e+02\n",
            "1.460e+02\n",
            "1.460e+02\n",
            "1.460e+02\n",
            "1.459e+02\n",
            "1.459e+02\n",
            "1.459e+02\n",
            "1.459e+02\n",
            "1.459e+02\n",
            "1.459e+02\n",
            "1.459e+02\n",
            "1.458e+02\n",
            "1.458e+02\n",
            "1.458e+02\n",
            "1.458e+02\n",
            "1.458e+02\n",
            "1.457e+02\n",
            "1.457e+02\n",
            "1.457e+02\n",
            "1.457e+02\n",
            "1.457e+02\n",
            "1.457e+02\n",
            "1.456e+02\n",
            "1.456e+02\n",
            "1.456e+02\n",
            "1.456e+02\n",
            "1.456e+02\n",
            "1.455e+02\n",
            "1.455e+02\n",
            "1.455e+02\n",
            "1.455e+02\n",
            "1.455e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.454e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.453e+02\n",
            "1.452e+02\n",
            "1.452e+02\n",
            "1.452e+02\n",
            "1.452e+02\n",
            "1.451e+02\n",
            "1.451e+02\n",
            "1.451e+02\n",
            "1.450e+02\n",
            "1.450e+02\n",
            "1.450e+02\n",
            "1.450e+02\n",
            "1.450e+02\n",
            "1.450e+02\n",
            "1.449e+02\n",
            "1.449e+02\n",
            "1.449e+02\n",
            "1.449e+02\n",
            "1.449e+02\n",
            "1.449e+02\n",
            "1.449e+02\n",
            "1.449e+02\n",
            "1.448e+02\n",
            "1.448e+02\n",
            "1.448e+02\n",
            "1.448e+02\n",
            "1.448e+02\n",
            "1.448e+02\n",
            "1.448e+02\n",
            "1.448e+02\n",
            "1.447e+02\n",
            "1.447e+02\n",
            "1.447e+02\n",
            "1.447e+02\n",
            "1.449e+02\n",
            "1.447e+02\n",
            "1.447e+02\n",
            "1.447e+02\n",
            "1.447e+02\n",
            "1.447e+02\n",
            "1.446e+02\n",
            "1.446e+02\n",
            "1.446e+02\n",
            "1.446e+02\n",
            "1.446e+02\n",
            "1.446e+02\n",
            "1.446e+02\n",
            "1.446e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.445e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.444e+02\n",
            "1.445e+02\n",
            "1.444e+02\n",
            "1.443e+02\n",
            "1.443e+02\n",
            "1.443e+02\n",
            "1.443e+02\n",
            "1.443e+02\n",
            "1.444e+02\n",
            "1.443e+02\n",
            "1.442e+02\n",
            "1.442e+02\n",
            "1.442e+02\n",
            "1.442e+02\n",
            "1.442e+02\n",
            "1.442e+02\n",
            "1.442e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.441e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.440e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.439e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.438e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.437e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "1.436e+02\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 143.582504\n",
            "  Number of iterations: 1379\n",
            "  Number of functions evaluations: 1543\n",
            "56.638413429260254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FljKmLh8bJ6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "vanderPol_Fig4_benchmark.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZL0JkBFD3OYl3oZ4BHSH7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}